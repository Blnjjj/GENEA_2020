## Обработка данных
Папка `DataProcessing` используется для работы с данными. В ней находятся следующие скрипты.
 
`process_motions.py` - скрипт конвертации BVH-файлов в фичи. За основу взят этот [скрипт](https://github.com/GestureGeneration/Speech_driven_gesture_generation_with_autoencoder/blob/GENEA_2020/data_processing/bvh2features.py).
Модуль `pymo` брался оттуда же, но основной репозиторий PyMo [тут](https://github.com/omimo/PyMO),
хотя в нем нет функции отражения по оси `Mirror`.

Собственно, что тут происходит:
- BVH-файлы считываются с помощью `pymo`
- К полученным данным применяется пайплайн `sklearn` со слудующими стадиями:
    - `dwnsampl` удаляет лишние кадры, чтобы соответсвовать требуемым FPS.
    - `root` переводит корневую вершину (Hips) в ноль
    - `mir` создает отраженную по оси X копию и добавляет в конец
    - `jtsel` оставляет только нужные части - верхнюю часть туловища с руками и головой
    - `exp` преобразует углы Эйлера в экспоненциальные карты
    - `cnst` дропает колонки с константами
    - `np` переводит в numpy-массив
- Полученные массивы сохраняются в файлы, отраженные отдельно. Итого для каждой исходной записи имеем 2 массива.

Флаг `--bvh` позволяет запустить скрипт в обратном режиме - сгенерировать BVH-файлы по фичам.

`visualization.ipynb` - ноутбук с примером, как исходный BVH-файл подготовить к отправке на сервер визуализации 
или визуализировать с помощью PyMO

`process_audio.py` - скрипт конвертации аудио-файлов в MFCC фичи.

После запуска `process_motions.py` и `process_audio.py` фичи еще будут не выровнены, 
поэтому после всего нужно выровнять и добавить контексты.

`align_data.py` - выравнивает данные и сохраняет их в numpy-архиве с ключами `X` и `Y`. Ключ `--with_context` отвечает
за генерацию аудио-данных с контекстом или без.
 
`prepare_data.bat` - Пример запуска подгототовки данных.

`cut_bvh.py` - принимает на вход BVH-файл, уменьшает фпс до 20 и урезает до 1200 кадров, чтобы потом отправить на 
сервер визуализации.